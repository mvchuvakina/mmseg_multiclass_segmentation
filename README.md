# Проект по обучению модели для мультиклассовой семантической сегментации

## Описание

В данном проекте была реализована задача мультиклассовой семантической сегментации с использованием библиотеки **mmsegmentation**. Модель должна была быть обучена на предоставленном датасете, с целью достижения метрики **mDice > 0.75** на тестовом наборе данных. Для этого были проведены несколько экспериментов, включая обучение моделей **DeepLabV3+** и **U-Net**, а также анализ данных с помощью методов **EDA**.

## Этапы работы

## Этап 1. Исследовательский анализ (EDA)

### Анализ качества данных

**Проверка целостности датасета:**

| Сплит | Изображения | Маски | Без масок | Без изображений | Полные пары |
|-------|------------|-------|-----------|-----------------|-------------|
| Train | 200 | 200 | 0 | 0 | 200 |
| Val   | 120 | 120 | 0 | 0 | 120 |
| Test  | 120 | 120 | 0 | 0 | 120 |

**Вывод:** Датасет полный, все изображения имеют соответствующие маски.

**Поиск ошибок в разметке:**
- Пустые маски: 0
- Маски только с фоном: 0
- Маски с одним классом: 200 шт. — особенность датасета

**Необходимость доразметки:** Не требуется.

---

### EDA

**1. Размеры изображений**  
Все изображения имеют фиксированный размер **256×256 пикселей**.

**2. Распределение классов (попиксельно)**

| Класс | Название | Пиксели | Доля |
|-------|---------|---------|------|
| 0 | Фон | 11,908,826 | 90.86% |
| 1 | Класс 1 | 653,268 | 4.98% |
| 2 | Класс 2 | 545,106 | 4.16% |

**Ключевая проблема:** Сильный дисбаланс классов, фон занимает >90% пикселей.

**3. Количество объектов на изображение**
- 1 объект: 200 изображений (100%)
- >1 объекта: 0 изображений

**4. Артефакты EDA**

| Файл | Описание |
|------|----------|
| `eda_results/class_distribution.png` | Распределение классов |
| `eda_results/image_sizes.png` | Размеры изображений |
| `eda_results/eda_summary.txt` | Полная статистика |

---

### Стратегия обучения на основе EDA

| № | Проблема | Решение |
|---|----------|---------|
| 1 | Дисбаланс классов | Взвешенный CrossEntropyLoss |
| 2 | Мало данных | Аугментации |
| 3 | Фиксированный размер | `img_size = 256` |
| 4 | 3 класса | `num_classes = 3` |

---

## Этап 2. Формирование первичных гипотез

### Стартовая гипотеза 1: DeepLabV3+ (Baseline)

**Модель:** `DeepLabV3+` с энкодером `ResNet-50`, предобученным на ImageNet.

**Обоснование выбора:**
- SOTA архитектура для семантической сегментации
- ASPP модуль эффективно захватывает контекст разных масштабов
- ResNet-50 — оптимальный баланс качества и скорости

**Функция потерь:** `CrossEntropyLoss` с весами классов  

class_weights = [0.1, 1.0, 1.0]  # фон, класс 1, класс 2

**Гиперпараметры**:

- Batch size:	8
- Learning rate:	1e-4
- Optimizer:	Adam
- Epochs:	30
- Image size:	256×256

**Аугментации**:
A.Compose([
    A.Resize(256, 256),
    A.HorizontalFlip(p=0.5),
    A.Rotate(limit=30, p=0.3),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ToTensorV2(),
])

ClearML эксперимент: https://app.clear.ml/projects/0e0b149e763b4360a236b92946d3452e/experiments/61113e663abf4d079860fa27dcba42fd/output/log

Конфиг: https://github.com/mvchuvakina/mmseg_multiclass_segmentation/configs/deeplabv3plus_best.json

### Стартовая гипотеза 2: U-Net с усиленными аугментациями

Модель: U-Net с энкодером ResNet-34, предобученным на ImageNet.
U-Net хорошо работает с малым количеством данных
Skip-соединения сохраняют пространственную информацию
ResNet-34 легче - меньше переобучения
Функция потерь: CrossEntropyLoss с весами классов
class_weights = [0.1, 1.2, 1.2]  # усиленный вес на редкие классы
**Гиперпараметры**:

Batch size:	8
Learning rate:	2e-4
Optimizer:	AdamW
Weight decay:	1e-4
Epochs:	30

**Aугментации**:

A.Compose([
    A.Resize(256, 256),
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.3),
    A.Rotate(limit=45, p=0.5),
    A.RandomBrightnessContrast(p=0.3),
    A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ToTensorV2(),
])
**Результаты обучения**

ClearML эксперимент: https://app.clear.ml/projects/8f224484f2c3459f8dd0fd9b0a5ad0e5/experiments/f82c9277b13248bc88dc671394fb99f8/output/log

Конфиг: https://github.com/mvchuvakina/mmseg_multiclass_segmentation/configs/deeplabv3plus_best.json

Вывод:
DeepLabV3+ достигла целевой метрики с запасом.
U-Net показала хороший результат, но немного не дотянула до цели.
DeepLabV3+ выбрана как лучшая модель.

### Этап 3. Анализ ошибок лучшей модели

Aнализ предсказаний DeepLabV3+

Ключевая проблема: Класс 2 игнорируется на сложных примерах (Dice = 0.000).

### Этап 4. Заключение и выбор лучшего эксперимента

Лучший эксперимент:

Модель: DeepLabV3+ с энкодером ResNet-50 (предобученным на ImageNet)

Функция потерь: CrossEntropyLoss с весами [0.1, 1.0, 1.0]

Оптимизатор: Adam, learning rate = 1e-4

Batch size: 8

Аугментации: HorizontalFlip (p=0.5), Rotate (p=0.3, limit=30)

Размер изображений: 256×256

Количество эпох: 30 (лучшая эпоха: 30)

## Структура проекта
Структура репозитория
```
mmsegmentation-project/
│
├── README.md                          # Отчёт по проекту
├── results.json                      # Итоговые метрики
│
├──  configs/                   # Основной код проекта
│                        # Конфигурации экспериментов
│   ├── deeplabv3plus_best.json
│   └── unet_best.json
│   │
 ── supplementary/               # Вспомогательные материалы
│   └── viz/                    # Визуализации для отчёта
│   │       ├── deeplabv3+/
│   │       └── unet/
│   
│ 
│
└── eda_results/                     # Результаты EDA
    ├── class_distribution.png
    ├── image_sizes.png
    └── eda_summary.txt

```

configs/deeplabv3plus_best.json	Конфигурация лучшей модели DeepLabV3+

configs/unet_best.json	Конфигурация лучшей модели U-Net

supplementary/viz/	Все визуализации для отчёта

results/detailed_comparison.json	Детальное сравнение моделей

eda_results/	Графики и статистика исследовательского анализа


